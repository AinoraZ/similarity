{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, h5py, os, shutil, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import saved_model\n",
    "from tensorflow.keras import backend, applications, optimizers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dropout, Flatten, Dense, Reshape\n",
    "from tensorflow.keras.callbacks import Callback, TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "from SimilarityConfigParser import SimilarityConfigParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "print(\"TensorFlow version: \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join('runtime_files', 'saved_model')\n",
    "checkpoint_auto_dir = os.path.join('runtime_files', 'auto_saved_model.h5')\n",
    "tensorboard_log_dir = os.path.join('runtime_files', 'logs', str(time()))\n",
    "\n",
    "config = SimilarityConfigParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "argN = 64\n",
    "train_folder = config.get_train_data_folder()\n",
    "test_folder = config.get_test_data_folder()\n",
    "\n",
    "train_dir_anchor = os.path.join(train_folder, 'train_a')\n",
    "train_dir_positive = os.path.join(train_folder, 'train_p')\n",
    "train_dir_negative = os.path.join(train_folder, 'train_n')\n",
    "\n",
    "valid_dir_anchor = os.path.join(train_folder, 'valid_a')\n",
    "valid_dir_positive = os.path.join(train_folder, 'valid_p')\n",
    "valid_dir_negative = os.path.join(train_folder, 'valid_n')\n",
    "\n",
    "test_dir_anchor = os.path.join(test_folder, 'test_a')\n",
    "test_dir_positive = os.path.join(test_folder, 'test_p')\n",
    "test_dir_negative = os.path.join(test_folder, 'test_n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator_triplet():\n",
    "    gen = ImageDataGenerator()\n",
    "    gen_a = gen.flow_from_directory(directory = train_dir_anchor, target_size = (224, 224), batch_size = 1, class_mode = 'categorical', shuffle = False)\n",
    "    gen_p = gen.flow_from_directory(directory = train_dir_positive, target_size = (224, 224), batch_size = 1, class_mode = 'categorical', shuffle = False)\n",
    "    gen_n = gen.flow_from_directory(directory = train_dir_negative, target_size = (224, 224), batch_size = 1, class_mode = 'categorical', shuffle = False)\n",
    "    while True:\n",
    "        an = gen_a.next()\n",
    "        po = gen_p.next()\n",
    "        ne = gen_n.next()\n",
    "        yield [an[0], po[0], ne[0]], an[1]\n",
    "\n",
    "def valid_generator_triplet():\n",
    "    gen = ImageDataGenerator()\n",
    "    gen_a = gen.flow_from_directory(directory = valid_dir_anchor, target_size = (224, 224), batch_size = 1, class_mode = 'categorical', shuffle = False)\n",
    "    gen_p = gen.flow_from_directory(directory = valid_dir_positive, target_size = (224, 224), batch_size = 1, class_mode = 'categorical', shuffle = False)\n",
    "    gen_n = gen.flow_from_directory(directory = valid_dir_negative, target_size = (224, 224), batch_size = 1, class_mode = 'categorical', shuffle = False)\n",
    "    while True:\n",
    "        an = gen_a.next()\n",
    "        po = gen_p.next()\n",
    "        ne = gen_n.next()\n",
    "        yield [an[0], po[0], ne[0]], an[1]\n",
    "\n",
    "def test_generator_triplet():\n",
    "    gen = ImageDataGenerator()\n",
    "    gen_a = gen.flow_from_directory(directory = test_dir_anchor, target_size = (224, 224), batch_size = 1, class_mode = 'categorical', shuffle = False)\n",
    "    gen_p = gen.flow_from_directory(directory = test_dir_positive, target_size = (224, 224), batch_size = 1, class_mode = 'categorical', shuffle = False)\n",
    "    gen_n = gen.flow_from_directory(directory = test_dir_negative, target_size = (224, 224), batch_size = 1, class_mode = 'categorical', shuffle = False)\n",
    "    while True:\n",
    "        an = gen_a.next()\n",
    "        po = gen_p.next()\n",
    "        ne = gen_n.next()\n",
    "        yield [an[0], po[0], ne[0]], an[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss & metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(N = argN, epsilon = 1e-6):\n",
    "    def triplet_loss(y_true, y_pred):\n",
    "        beta = N\n",
    "        print(y_pred.get_shape())\n",
    "\n",
    "        anchor = y_pred[0::3]\n",
    "        positive = y_pred[1::3]\n",
    "        negative = y_pred[2::3]\n",
    "\n",
    "        positive_distance = tf.reduce_sum(input_tensor=tf.square(tf.subtract(anchor, positive)), axis = 0, keepdims = True)\n",
    "        negative_distance = tf.reduce_sum(input_tensor=tf.square(tf.subtract(anchor, negative)), axis = 0, keepdims = True)\n",
    "\n",
    "        positive_distance = -tf.math.log(-tf.math.divide((positive_distance), beta) + 1 + epsilon)\n",
    "        negative_distance = -tf.math.log(-tf.math.divide((N - negative_distance), beta) + 1 + epsilon)\n",
    "\n",
    "        loss = negative_distance + positive_distance\n",
    "        return loss\n",
    "    return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd(N = argN, epsilon = 1e-6):\n",
    "    def pd(y_true, y_pred):\n",
    "        beta = N\n",
    "        anchor = y_pred[0::3]\n",
    "        positive = y_pred[1::3]\n",
    "        positive_distance = tf.reduce_sum(input_tensor=tf.square(tf.subtract(anchor, positive)), axis=0)\n",
    "        positive_distance = -tf.math.log(-tf.math.divide((positive_distance), beta) + 1 + epsilon)\n",
    "        return backend.mean(positive_distance)\n",
    "    return pd\n",
    "\n",
    "def nd(N = argN, epsilon = 1e-06):\n",
    "    def nd(y_true, y_pred):\n",
    "        beta = N\n",
    "        anchor = y_pred[0::3]\n",
    "        negative = y_pred[2::3]\n",
    "        negative_distance = tf.reduce_sum(input_tensor=tf.square(tf.subtract(anchor, negative)), axis=0)\n",
    "        negative_distance = -tf.math.log(-tf.math.divide((N - negative_distance), beta) + 1 + epsilon)\n",
    "        return backend.mean(negative_distance)\n",
    "    return nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    input_a = Input(shape = (224, 224, 3),  name = 'input_a')\n",
    "    input_p = Input(shape = (224, 224, 3),  name = 'input_p')\n",
    "    input_n = Input(shape = (224, 224, 3),  name = 'input_n')\n",
    "\n",
    "    base_model = applications.VGG16(include_top = False, weights = 'imagenet')\n",
    "\n",
    "    l1_a = base_model.layers[0](input_a)\n",
    "    l1_p = base_model.layers[0](input_p)\n",
    "    l1_n = base_model.layers[0](input_n)\n",
    "\n",
    "    l2_a = base_model.layers[1](l1_a)\n",
    "    l2_p = base_model.layers[1](l1_p)\n",
    "    l2_n = base_model.layers[1](l1_n)\n",
    "\n",
    "    l3_a = base_model.layers[2](l2_a)\n",
    "    l3_p = base_model.layers[2](l2_p)\n",
    "    l3_n = base_model.layers[2](l2_n)\n",
    "\n",
    "    l4_a = base_model.layers[3](l3_a)\n",
    "    l4_p = base_model.layers[3](l3_p)\n",
    "    l4_n = base_model.layers[3](l3_n)\n",
    "\n",
    "    l5_a = base_model.layers[4](l4_a)\n",
    "    l5_p = base_model.layers[4](l4_p)\n",
    "    l5_n = base_model.layers[4](l4_n)\n",
    "\n",
    "    l6_a = base_model.layers[5](l5_a)\n",
    "    l6_p = base_model.layers[5](l5_p)\n",
    "    l6_n = base_model.layers[5](l5_n)\n",
    "\n",
    "    l7_a = base_model.layers[6](l6_a)\n",
    "    l7_p = base_model.layers[6](l6_p)\n",
    "    l7_n = base_model.layers[6](l6_n)\n",
    "\n",
    "    l8_a = base_model.layers[7](l7_a)\n",
    "    l8_p = base_model.layers[7](l7_p)\n",
    "    l8_n = base_model.layers[7](l7_n)\n",
    "\n",
    "    l9_a = base_model.layers[8](l8_a)\n",
    "    l9_p = base_model.layers[8](l8_p)\n",
    "    l9_n = base_model.layers[8](l8_n)\n",
    "\n",
    "    lt1 = Dense(64, activation = 'sigmoid')\n",
    "    lt2 = Dropout(0.5)\n",
    "    lt3 = Dense(8, activation = 'sigmoid')\n",
    "\n",
    "    lt1_a = lt1(l9_a)\n",
    "    lt1_p = lt1(l9_p)\n",
    "    lt1_n = lt1(l9_n)\n",
    "\n",
    "    lt2_a = lt2(lt1_a)\n",
    "    lt2_p = lt2(lt1_p)\n",
    "    lt2_n = lt2(lt1_n)\n",
    "\n",
    "    lt3_a = lt3(lt2_a)\n",
    "    lt3_p = lt3(lt2_p)\n",
    "    lt3_n = lt3(lt2_n)\n",
    "\n",
    "    output = tf.keras.layers.concatenate([lt3_a, lt3_p, lt3_n], axis = 0, name = 'out666')\n",
    "    model = tf.keras.models.Model(inputs = [input_a, input_p, input_n], outputs = output)\n",
    "\n",
    "    for layer in model.layers:\n",
    "        if layer.name == 'dense':\n",
    "            break\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer = optimizers.Adam(), loss = triplet_loss(), metrics = [pd(), nd()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    model = make_model()\n",
    "\n",
    "    cb_tensorboard = TensorBoard(log_dir = tensorboard_log_dir, histogram_freq = 2, write_graph = True, write_images = True)\n",
    "    cb_checkpoint = ModelCheckpoint(checkpoint_auto_dir, save_weights_only = False, period = 100, verbose = 1)\n",
    "\n",
    "    model.fit_generator(generator = train_generator_triplet(), steps_per_epoch = argN, epochs = args.epochs, validation_data = valid_generator_triplet(), validation_steps = 3, callbacks = [cb_tensorboard, cb_checkpoint])\n",
    "    model.save(checkpoint_dir, save_format='tf')\n",
    "\n",
    "def test_model():\n",
    "    test_samples = len(os.listdir(os.path.join(test_dir_anchor, \"0\")))\n",
    "    model = tf.keras.models.load_model(checkpoint_dir, compile=False)\n",
    "    model.compile(optimizer = optimizers.Adam(), loss = triplet_loss(), metrics = [pd(), nd()])\n",
    "\n",
    "    results = model.predict_generator(generator = test_generator_triplet(), steps = test_samples, verbose = 0)\n",
    "\n",
    "    beta = argN\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    anchor = results[0::3]\n",
    "    positive = results[1::3]\n",
    "    negative = results[2::3]\n",
    "\n",
    "    positive_distance = np.nansum(np.square(anchor - positive), axis = 1)\n",
    "    positive_distance = - np.log(- (positive_distance / beta) + 1 + epsilon)\n",
    "\n",
    "    negative_distance = np.nansum(np.square(anchor - negative), axis = 1)\n",
    "    negative_distance = - np.log(- (negative_distance / beta) + 1 + epsilon)\n",
    "\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    pneq = 0\n",
    "    min_p = sys.maxsize\n",
    "    max_p = 0\n",
    "    min_n = sys.maxsize\n",
    "    max_n = 0\n",
    "\n",
    "    for i in range(test_samples):\n",
    "        pda = np.nansum(positive_distance[i])\n",
    "        nda = np.nansum(negative_distance[i])\n",
    "        print(pda, \"\\t\", nda)\n",
    "    if pda >= nda:\n",
    "        fp += 1\n",
    "    else:\n",
    "        tp += 1\n",
    "    if pda == nda:\n",
    "        pneq += 1\n",
    "\n",
    "    if min_p > pda:\n",
    "        min_p = pda\n",
    "    if max_p < pda:\n",
    "        max_p = pda\n",
    "\n",
    "    if min_n > nda:\n",
    "        min_n = nda\n",
    "    if max_n < nda:\n",
    "        max_n = nda\n",
    "\n",
    "    print(min_p, ' - ', max_p, ', ', min_n, ' - ', max_n)\n",
    "    print('accuracy: ', np.round(tp / (tp + fp) * 100, 1))\n",
    "    print('equal predictions: ', pneq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history, metrics=['loss'], skip_start=0.):\n",
    "    \"\"\"\n",
    "    Plots metrics from keras training history.\n",
    "    \"\"\"\n",
    "    hist = history.history\n",
    "    start_indice = int(len(hist[metrics[0]]) * skip_start)\n",
    "    \n",
    "    for metric in metrics:\n",
    "        plt.plot(hist[metric][start_indice:], label=\"train {}\".format(metric))\n",
    "        plt.plot(hist[f\"val_{metric}\"][start_indice:], label=f\"val {metric}\")\n",
    "        plt.legend()\n",
    "        plt.title(metric)\n",
    "        plt.figure()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the callbacks. Added 2 additional callbacks for training:\n",
    "  - `EarlyStopping` - stops the model once it's no longer getting better at validation data\n",
    "  - `ReduceLROnPlateau` - reduces learning rate when model doesn't improve on the validation data for some period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "#     TensorBoard(log_dir = tensorboard_log_dir, histogram_freq = 2, write_graph = True, write_images = True),\n",
    "#     ModelCheckpoint(checkpoint_auto_dir, save_weights_only = False, period = 100, verbose = 1),\n",
    "    EarlyStopping(patience=15, verbose=1, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(factor=0.5, patience=3, verbose=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 56, 56, 8)\n",
      "Found 1188 images belonging to 1 classes.\n",
      "Found 1188 images belonging to 1 classes.\n",
      "Found 1188 images belonging to 1 classes.\n",
      "Found 105 images belonging to 1 classes.\n",
      "Found 105 images belonging to 1 classes.\n",
      "Found 105 images belonging to 1 classes.\n",
      "Train for 1252 steps, validate for 100 steps\n",
      "Epoch 1/100\n",
      "(None, 56, 56, 8)\n",
      "(None, 56, 56, 8)\n",
      "1249/1252 [============================>.] - ETA: 0s - loss: 6.9648 - pd: 0.0033 - nd: 6.9615(None, 56, 56, 8)\n",
      "1252/1252 [==============================] - 20s 16ms/step - loss: 6.9644 - pd: 0.0033 - nd: 6.9611 - val_loss: 7.6871 - val_pd: 0.0013 - val_nd: 7.6858\n",
      "Epoch 2/100\n",
      "1252/1252 [==============================] - 18s 14ms/step - loss: 6.4194 - pd: 0.0036 - nd: 6.4157 - val_loss: 4.9548 - val_pd: 0.0023 - val_nd: 4.9525\n",
      "Epoch 3/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.9180 - pd: 0.0019 - nd: 4.9162 - val_loss: 4.6281 - val_pd: 0.0027 - val_nd: 4.6254\n",
      "Epoch 4/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.6843 - pd: 0.0017 - nd: 4.6825 - val_loss: 4.5798 - val_pd: 0.0020 - val_nd: 4.5778\n",
      "Epoch 5/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.6283 - pd: 0.0017 - nd: 4.6266 - val_loss: 4.5887 - val_pd: 0.0022 - val_nd: 4.5864\n",
      "Epoch 6/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.6167 - pd: 0.0018 - nd: 4.6150 - val_loss: 4.7729 - val_pd: 0.0040 - val_nd: 4.7689\n",
      "Epoch 7/100\n",
      "1249/1252 [============================>.] - ETA: 0s - loss: 4.5780 - pd: 0.0018 - nd: 4.5762\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5782 - pd: 0.0018 - nd: 4.5764 - val_loss: 4.6458 - val_pd: 0.0038 - val_nd: 4.6420\n",
      "Epoch 8/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5479 - pd: 0.0018 - nd: 4.5461 - val_loss: 4.6247 - val_pd: 0.0038 - val_nd: 4.6209\n",
      "Epoch 9/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5155 - pd: 0.0017 - nd: 4.5138 - val_loss: 4.7492 - val_pd: 0.0042 - val_nd: 4.7450\n",
      "Epoch 10/100\n",
      "1249/1252 [============================>.] - ETA: 0s - loss: 4.4967 - pd: 0.0018 - nd: 4.4949\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4963 - pd: 0.0018 - nd: 4.4946 - val_loss: 4.9165 - val_pd: 0.0045 - val_nd: 4.9120\n",
      "Epoch 11/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5116 - pd: 0.0018 - nd: 4.5099 - val_loss: 4.6154 - val_pd: 0.0043 - val_nd: 4.6112\n",
      "Epoch 12/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5128 - pd: 0.0019 - nd: 4.5109 - val_loss: 4.3987 - val_pd: 0.0026 - val_nd: 4.3961\n",
      "Epoch 13/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4885 - pd: 0.0020 - nd: 4.4865 - val_loss: 4.3883 - val_pd: 0.0022 - val_nd: 4.3861\n",
      "Epoch 14/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4830 - pd: 0.0020 - nd: 4.4811 - val_loss: 4.4410 - val_pd: 0.0017 - val_nd: 4.4392\n",
      "Epoch 15/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4730 - pd: 0.0020 - nd: 4.4711 - val_loss: 4.3934 - val_pd: 0.0023 - val_nd: 4.3910\n",
      "Epoch 16/100\n",
      "1249/1252 [============================>.] - ETA: 0s - loss: 4.4775 - pd: 0.0019 - nd: 4.4756\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4773 - pd: 0.0019 - nd: 4.4754 - val_loss: 4.4044 - val_pd: 0.0020 - val_nd: 4.4024\n",
      "Epoch 17/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4944 - pd: 0.0020 - nd: 4.4923 - val_loss: 4.4109 - val_pd: 0.0017 - val_nd: 4.4092\n",
      "Epoch 18/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4930 - pd: 0.0020 - nd: 4.4910 - val_loss: 4.4526 - val_pd: 0.0017 - val_nd: 4.4509\n",
      "Epoch 19/100\n",
      "1249/1252 [============================>.] - ETA: 0s - loss: 4.4794 - pd: 0.0020 - nd: 4.4774\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4798 - pd: 0.0020 - nd: 4.4778 - val_loss: 4.4125 - val_pd: 0.0019 - val_nd: 4.4106\n",
      "Epoch 20/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5025 - pd: 0.0020 - nd: 4.5005 - val_loss: 4.3853 - val_pd: 0.0022 - val_nd: 4.3831\n",
      "Epoch 21/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4971 - pd: 0.0020 - nd: 4.4950 - val_loss: 4.3701 - val_pd: 0.0022 - val_nd: 4.3678\n",
      "Epoch 22/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4914 - pd: 0.0021 - nd: 4.4893 - val_loss: 4.3708 - val_pd: 0.0024 - val_nd: 4.3684\n",
      "Epoch 23/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4921 - pd: 0.0021 - nd: 4.4900 - val_loss: 4.3932 - val_pd: 0.0021 - val_nd: 4.3911\n",
      "Epoch 24/100\n",
      "1249/1252 [============================>.] - ETA: 0s - loss: 4.4917 - pd: 0.0021 - nd: 4.4897\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4924 - pd: 0.0021 - nd: 4.4904 - val_loss: 4.3748 - val_pd: 0.0025 - val_nd: 4.3724\n",
      "Epoch 25/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5238 - pd: 0.0022 - nd: 4.5216 - val_loss: 4.3687 - val_pd: 0.0026 - val_nd: 4.3662\n",
      "Epoch 26/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5112 - pd: 0.0022 - nd: 4.5090 - val_loss: 4.3693 - val_pd: 0.0028 - val_nd: 4.3665\n",
      "Epoch 27/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5037 - pd: 0.0022 - nd: 4.5015 - val_loss: 4.3924 - val_pd: 0.0031 - val_nd: 4.3893\n",
      "Epoch 28/100\n",
      "1249/1252 [============================>.] - ETA: 0s - loss: 4.4978 - pd: 0.0022 - nd: 4.4957\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4973 - pd: 0.0022 - nd: 4.4952 - val_loss: 4.4136 - val_pd: 0.0035 - val_nd: 4.4101\n",
      "Epoch 29/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5130 - pd: 0.0023 - nd: 4.5107 - val_loss: 4.3568 - val_pd: 0.0033 - val_nd: 4.3535\n",
      "Epoch 30/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5053 - pd: 0.0022 - nd: 4.5031 - val_loss: 4.3921 - val_pd: 0.0034 - val_nd: 4.3887\n",
      "Epoch 31/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5048 - pd: 0.0025 - nd: 4.5024 - val_loss: 4.3893 - val_pd: 0.0032 - val_nd: 4.3861\n",
      "Epoch 32/100\n",
      "1249/1252 [============================>.] - ETA: 0s - loss: 4.5005 - pd: 0.0025 - nd: 4.4980\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5001 - pd: 0.0025 - nd: 4.4976 - val_loss: 4.3811 - val_pd: 0.0031 - val_nd: 4.3780\n",
      "Epoch 33/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5074 - pd: 0.0026 - nd: 4.5048 - val_loss: 4.3713 - val_pd: 0.0030 - val_nd: 4.3683\n",
      "Epoch 34/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4987 - pd: 0.0024 - nd: 4.4963 - val_loss: 4.3727 - val_pd: 0.0028 - val_nd: 4.3699\n",
      "Epoch 35/100\n",
      "1249/1252 [============================>.] - ETA: 0s - loss: 4.4987 - pd: 0.0024 - nd: 4.4963\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4983 - pd: 0.0024 - nd: 4.4958 - val_loss: 4.3671 - val_pd: 0.0028 - val_nd: 4.3643\n",
      "Epoch 36/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5318 - pd: 0.0025 - nd: 4.5293 - val_loss: 4.3691 - val_pd: 0.0028 - val_nd: 4.3663\n",
      "Epoch 37/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4973 - pd: 0.0025 - nd: 4.4948 - val_loss: 4.3708 - val_pd: 0.0030 - val_nd: 4.3678\n",
      "Epoch 38/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4961 - pd: 0.0023 - nd: 4.4938 - val_loss: 4.3480 - val_pd: 0.0029 - val_nd: 4.3451\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4982 - pd: 0.0023 - nd: 4.4959 - val_loss: 4.3585 - val_pd: 0.0030 - val_nd: 4.3555\n",
      "Epoch 40/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4963 - pd: 0.0023 - nd: 4.4940 - val_loss: 4.3658 - val_pd: 0.0028 - val_nd: 4.3631\n",
      "Epoch 41/100\n",
      "1249/1252 [============================>.] - ETA: 0s - loss: 4.4962 - pd: 0.0023 - nd: 4.4939\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4959 - pd: 0.0023 - nd: 4.4936 - val_loss: 4.3643 - val_pd: 0.0028 - val_nd: 4.3615\n",
      "Epoch 42/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5017 - pd: 0.0022 - nd: 4.4995 - val_loss: 4.3630 - val_pd: 0.0028 - val_nd: 4.3602\n",
      "Epoch 43/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5098 - pd: 0.0023 - nd: 4.5076 - val_loss: 4.3668 - val_pd: 0.0027 - val_nd: 4.3641\n",
      "Epoch 44/100\n",
      "1249/1252 [============================>.] - ETA: 0s - loss: 4.5089 - pd: 0.0023 - nd: 4.5067\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5088 - pd: 0.0023 - nd: 4.5066 - val_loss: 4.3616 - val_pd: 0.0027 - val_nd: 4.3589\n",
      "Epoch 45/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5029 - pd: 0.0022 - nd: 4.5007 - val_loss: 4.3612 - val_pd: 0.0028 - val_nd: 4.3584\n",
      "Epoch 46/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5019 - pd: 0.0022 - nd: 4.4996 - val_loss: 4.3663 - val_pd: 0.0030 - val_nd: 4.3633\n",
      "Epoch 47/100\n",
      "1249/1252 [============================>.] - ETA: 0s - loss: 4.5033 - pd: 0.0022 - nd: 4.5010\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5036 - pd: 0.0022 - nd: 4.5013 - val_loss: 4.3534 - val_pd: 0.0030 - val_nd: 4.3504\n",
      "Epoch 48/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5027 - pd: 0.0022 - nd: 4.5005 - val_loss: 4.3596 - val_pd: 0.0030 - val_nd: 4.3566\n",
      "Epoch 49/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5043 - pd: 0.0023 - nd: 4.5020 - val_loss: 4.3682 - val_pd: 0.0028 - val_nd: 4.3654\n",
      "Epoch 50/100\n",
      "1249/1252 [============================>.] - ETA: 0s - loss: 4.4922 - pd: 0.0025 - nd: 4.4897\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4917 - pd: 0.0025 - nd: 4.4893 - val_loss: 4.3631 - val_pd: 0.0029 - val_nd: 4.3602\n",
      "Epoch 51/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.5020 - pd: 0.0025 - nd: 4.4995 - val_loss: 4.3656 - val_pd: 0.0029 - val_nd: 4.3627\n",
      "Epoch 52/100\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4907 - pd: 0.0025 - nd: 4.4882 - val_loss: 4.3653 - val_pd: 0.0027 - val_nd: 4.3626\n",
      "Epoch 53/100\n",
      "1249/1252 [============================>.] - ETA: 0s - loss: 4.4980 - pd: 0.0024 - nd: 4.4956Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "1252/1252 [==============================] - 18s 15ms/step - loss: 4.4977 - pd: 0.0024 - nd: 4.4953 - val_loss: 4.3669 - val_pd: 0.0028 - val_nd: 4.3640\n",
      "Epoch 00053: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generator = train_generator_triplet(), \n",
    "    steps_per_epoch = 1252, \n",
    "    epochs = 100, \n",
    "    validation_data = valid_generator_triplet(), \n",
    "    validation_steps = 100, \n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metrics(history, metrics=['loss',], skip_start=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`test_model` function not fixed yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
